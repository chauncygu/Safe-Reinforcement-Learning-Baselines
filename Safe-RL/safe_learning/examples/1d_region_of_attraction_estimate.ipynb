{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability verification of a fixed uncertain system (without dynamic programming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from future.builtins import *\n",
    "from functools import partial\n",
    "%matplotlib inline\n",
    "\n",
    "import plotting\n",
    "import safe_learning\n",
    "\n",
    "try:\n",
    "    session.close()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "graph = tf.Graph()\n",
    "session = tf.InteractiveSession(graph=graph)\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a discretization of the space $[-1, 1]$ with discretization constant $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretization = safe_learning.GridWorld([-1, 1], 1001)\n",
    "tau = 1 / discretization.nindex\n",
    "\n",
    "print('Grid size: {0}'.format(discretization.nindex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the GP model using one particular sample of the GP, in addition to a stable, closed-loop, linear model.\n",
    "$$x_{l+1} = 0.25 x_k + g_\\pi(x),$$\n",
    "\n",
    "The prior dynamics are locally asymptotically stable. Moreover, in the one-dimensional case, the dynamics are stable as long as $|x_{k+1}| \\leq |x_{k}|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation noise\n",
    "noise_var = 0.01 ** 2\n",
    "\n",
    "with tf.variable_scope('gp'):\n",
    "    # Mean dynamics\n",
    "    mean_function = safe_learning.LinearSystem((0.25, 0.), name='mean_dynamics')\n",
    "\n",
    "    kernel = (gpflow.kernels.Matern32(1, lengthscales=1, variance=0.4**2, active_dims=[0])\n",
    "              * gpflow.kernels.Linear(1, active_dims=[0]))\n",
    "\n",
    "    gp = safe_learning.GPRCached(np.empty((0, 2), dtype=safe_learning.config.np_dtype),\n",
    "                        np.empty((0, 1), dtype=safe_learning.config.np_dtype),\n",
    "                        kernel,\n",
    "                        mean_function=mean_function)\n",
    "    gp.likelihood.variance = noise_var\n",
    "\n",
    "    gpfun = safe_learning.GaussianProcess(gp, name='gp_dynamics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define one sample as the true dynamics\n",
    "np.random.seed(5)\n",
    "\n",
    "# # Set up a discretization\n",
    "sample_disc = np.hstack((np.linspace(-1, 1, 50)[:, None],\n",
    "                         np.zeros((50, 1))))\n",
    "\n",
    "# # Draw samples\n",
    "fs = safe_learning.sample_gp_function(sample_disc, gpfun, number=10, return_function=False)\n",
    "plt.plot(sample_disc[:, 0], fs.T)\n",
    "\n",
    "plt.ylabel('$g(x)$')\n",
    "plt.xlabel('x')\n",
    "plt.title('Samples drawn from the GP model of the dynamics')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "true_dynamics = safe_learning.sample_gp_function(\n",
    "    sample_disc,\n",
    "    gpfun)[0]\n",
    "\n",
    "# Plot the basic model\n",
    "with tf.variable_scope('plot_true_dynamics'):\n",
    "    true_y = true_dynamics(sample_disc, noise=False).eval(feed_dict=true_dynamics.feed_dict)\n",
    "plt.plot(sample_disc[:, 0], true_y, color='black', alpha=0.8)\n",
    "plt.title('GP model of the dynamics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyapunov_function = safe_learning.QuadraticFunction(np.array([[1]]))\n",
    "lyapunov_disc = safe_learning.GridWorld([-1., 1.], 3)\n",
    "lyapunov_function = safe_learning.Triangulation(lyapunov_disc, [1, 0, 1], name='lyapunov_function')\n",
    "\n",
    "dynamics = gpfun\n",
    "policy = safe_learning.LinearSystem(np.array([0.]), name='policy')\n",
    "\n",
    "# Lipschitz constant\n",
    "# L_dyn = 0.25 + dynamics.beta(0) * np.sqrt(gp.kern.Mat32.variance) / gp.kern.Mat32.lengthscale * np.max(np.abs(extent))\n",
    "# L_V = np.max(lyapunov_function.gradient(grid))\n",
    "\n",
    "L_dyn = 0.25\n",
    "L_V = 1.\n",
    "\n",
    "lyapunov = safe_learning.Lyapunov(discretization, lyapunov_function, dynamics, L_dyn, L_V, tau, policy)\n",
    "\n",
    "# Specify the desired accuracy\n",
    "# accuracy = np.max(lyapunov.V) / 1e10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safety based on GP model\n",
    "\n",
    "Let's start by plotting the prior over the dynamics and the associated prior over $\\dot{V}(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyapunov.update_safe_set()\n",
    "plotting.plot_lyapunov_1d(lyapunov, true_dynamics, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the model does not allow us to classify any states as safe ($\\dot{V} < -L \\tau$). However, as a starting point, we assume that we know that the system is asymptotially stable within some initial set, $\\mathcal{S}_0$:\n",
    "\n",
    "$$\\mathcal{S}_0 = \\{ x \\in \\mathbb{R} \\,|\\, |x| < 0.2 \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyapunov.initial_safe_set = np.abs(lyapunov.discretization.all_points.squeeze()) < 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online learning\n",
    "As we sample within this initial safe set, we gain more knowledge about the system. In particular, we iteratively select the state withing the safe set, $\\mathcal{S}_n$, where the dynamics are the most uncertain (highest variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = lyapunov.discretization.all_points\n",
    "lyapunov.update_safe_set()\n",
    "\n",
    "with tf.variable_scope('sample_new_safe_point'):\n",
    "    safe_set = tf.placeholder(safe_learning.config.dtype, [None, None])\n",
    "    _, dynamics_std_tf = lyapunov.dynamics(safe_set, lyapunov.policy(safe_set))\n",
    "    \n",
    "                                           \n",
    "    tf_max_state = tf.placeholder(safe_learning.config.dtype, [1, None])\n",
    "    tf_max_action = lyapunov.policy(tf_max_state)\n",
    "    tf_measurement = true_dynamics(tf_max_state, tf_max_action)\n",
    "    \n",
    "feed_dict = lyapunov.dynamics.feed_dict\n",
    "                                        \n",
    "def update_gp():\n",
    "    \"\"\"Update the GP model based on an actively selected data point.\"\"\"\n",
    "    # Maximum uncertainty in safe set\n",
    "    safe_grid = grid[lyapunov.safe_set]\n",
    "                                        \n",
    "    feed_dict[safe_set] = safe_grid\n",
    "    dynamics_std = dynamics_std_tf.eval(feed_dict=feed_dict)\n",
    "    \n",
    "    max_id = np.argmax(dynamics_std)\n",
    "    max_state = safe_grid[[max_id], :].copy()\n",
    "                                           \n",
    "    feed_dict[tf_max_state] = max_state\n",
    "    max_action, measurement = session.run([tf_max_action, tf_measurement],\n",
    "                                          feed_dict=feed_dict)\n",
    "                                   \n",
    "    arg = np.hstack((max_state, max_action))\n",
    "    lyapunov.dynamics.add_data_point(arg, measurement)\n",
    "    lyapunov.update_safe_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the GP model a couple of times\n",
    "for i in range(4):\n",
    "    update_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the new safe set\n",
    "plotting.plot_lyapunov_1d(lyapunov, true_dynamics, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue to sample like this, until we find the maximum safe set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    update_gp()\n",
    "\n",
    "lyapunov.update_safe_set()\n",
    "plotting.plot_lyapunov_1d(lyapunov, true_dynamics, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
